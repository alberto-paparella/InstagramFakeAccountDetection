{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Fake Account Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 17:41:51.799886: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 17:41:51.840050: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:7630] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-06-29 17:41:51.840083: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-06-29 17:41:51.840103: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-29 17:41:51.847390: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 17:41:51.848031: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 17:41:52.665317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/alberto/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alberto/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/alberto/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "from dataset.normalizer import json_importer_full\n",
    "from dataset.utils import shuffle_and_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deep.IJECE.IJECE_custom import run_model as run_ijce_custom\n",
    "from deep.IJECE.IJECE_default import run_model as run_ijce_default\n",
    "from deep.spz.spz_default import run_model as run_spz_default\n",
    "from deep.spz.spz_custom import run_model as run_spz_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.disable_interactive_logging()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading from file ./dataset/sources/automatedAccountData.json...\n",
      "Loaded 700 entries from source ./dataset/sources/automatedAccountData.json\n",
      "Now loading from file ./dataset/sources/nonautomatedAccountData.json...\n",
      "Loaded 700 entries from source ./dataset/sources/nonautomatedAccountData.json\n"
     ]
    }
   ],
   "source": [
    "fake = json_importer_full(\"./dataset/sources/automatedAccountData.json\", True)\n",
    "correct = json_importer_full(\"./dataset/sources/nonautomatedAccountData.json\", False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 29 - 06"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXP = 500 # Number of experiments\n",
    "MAX_ITER = 50000 # Maximum number of iterations for LR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using custom experiment functions not to mess up with the real experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Drop target columns from dataset\n",
    "'''\n",
    "def get_custom_dataset(train_df, validation_df, column_names=[]):\n",
    "    custom_train_df = train_df.drop(column_names, axis=1)\n",
    "    custom_validation_df = validation_df.drop(column_names, axis=1)\n",
    "\n",
    "    return custom_train_df, custom_validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_val, y_pred):\n",
    "    scores = {\n",
    "        'accuracy': 0,\n",
    "        'precision': 0,\n",
    "        'recall': 0,\n",
    "        'f1': 0\n",
    "    }\n",
    "    scores['accuracy'] += metrics.accuracy_score(y_val, y_pred)\n",
    "    scores['precision'] += metrics.precision_score(y_val, y_pred)\n",
    "    scores['recall'] += metrics.recall_score(y_val, y_pred)\n",
    "    scores['f1'] += metrics.f1_score(y_val, y_pred)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(x, y_i, y):\n",
    "    \"\"\"Naive-Bayes function\"\"\"\n",
    "    p = x[y == y_i].sum(0)\n",
    "    return (p + 1) / ((y == y_i).sum() + 1)\n",
    "\n",
    "\n",
    "def naive_bayes_support_vector_machine(x, y):\n",
    "    y = y.values\n",
    "    r = np.log(naive_bayes(x, 1, y) / naive_bayes(x, 0, y))\n",
    "    # m = LogisticRegression(C=4, dual=True) # This gives an error\n",
    "    m = LogisticRegression(C=4, dual=False, max_iter=MAX_ITER)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(fake, correct, column_names=[], mode=\"dt\", n_iter=20, demarcator=700):\n",
    "    '''\n",
    "    A function which execution an experiment fitting a model `n_iter` times and giving\n",
    "    back the `avg_scores` for various metrics such as `accuracy`, `precision`, `recall`, ...\n",
    "\n",
    "    `modes`:\n",
    "    - `dt` => DecisionTree\n",
    "    - `lr` => LogisticRegression\n",
    "    - `nb` => NaiveBayes (NB-SVM, but using LogisticRegression instead)\n",
    "    - `rf` => RandomForest approach\n",
    "    - `dl` => DeepLearning approach using neural networks\n",
    "    '''\n",
    "    avg_scores = {\n",
    "        'default': {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0},\n",
    "        'custom': {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
    "    }\n",
    "\n",
    "    if mode == \"dt\":\n",
    "        print(f\"Calculating metrics for Decision Trees over {n_iter} times\")\n",
    "    elif mode == \"lr\":\n",
    "        print(f\"Calculating metrics for Logistic Regression over {n_iter} times\")\n",
    "    elif mode == \"nb\":\n",
    "        print(f\"Calculating metrics for Naive Bayes (Logistic Regression) over {n_iter} times\")\n",
    "    elif mode == \"rf\":\n",
    "        print(f\"Calculating metrics for Random Forests over {n_iter} times\")\n",
    "    elif mode == \"dl\":\n",
    "        print(f\"Calculating metrics for Deep Learning over {n_iter} times\")\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # Get new train_df and validation_df, same for default and custom\n",
    "        train_df, validation_df = shuffle_and_split(fake, correct)\n",
    "        custom_train_df, custom_validation_df = get_custom_dataset(train_df, validation_df, column_names)\n",
    "        # Default mode\n",
    "        if mode == \"dt\":\n",
    "            # Get new Decision Tree\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf = clf.fit(train_df.iloc[:, :-1], train_df.iloc[:, -1])\n",
    "        elif mode == \"lr\":\n",
    "            # Get new Logistic Regressor\n",
    "            clf = LogisticRegression(random_state=0, max_iter=MAX_ITER)\n",
    "            clf = clf.fit(train_df.iloc[:, :-1], train_df.iloc[:, -1])\n",
    "        elif mode == \"nb\":\n",
    "            '''\n",
    "            Here we try using NBSVM (Naive Bayes - Support Vector Machine) but using sklearn's logistic regression rather than SVM,\n",
    "            although in practice the two are nearly identical. NBSVM was introduced by Sida Wang and Chris Manning in the paper\n",
    "            [Baselines and Bigrams: Simple, Good Sentiment and Topic ClassiÔ¨Åcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf).\n",
    "            '''\n",
    "            clf, r = naive_bayes_support_vector_machine(train_df.iloc[:, :-1], train_df.iloc[:, -1])\n",
    "        elif mode == \"rf\":\n",
    "            clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "            clf = clf.fit(train_df.iloc[:, :-1], train_df.iloc[:, -1])\n",
    "        elif mode == \"dl\":\n",
    "            print(f\"Training default model {i + 1}/{n_iter}      \", end=\"\\r\")\n",
    "            # Get new DL\n",
    "            clf = run_spz_default(train_df)\n",
    "\n",
    "        # Get ground truth and predictions to measure performance\n",
    "        X_val, y_val = validation_df.iloc[:, :-1], validation_df.iloc[:, -1]\n",
    "        if mode == \"dl\":\n",
    "            accuracy = 0\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            n = 100\n",
    "            for _ in range(n):\n",
    "                _, acc, prc, rec = clf.evaluate(x=X_val, y=y_val, verbose=0)\n",
    "                accuracy += acc\n",
    "                precision += prc\n",
    "                recall += rec\n",
    "            avg_scores['default']['accuracy'] += accuracy / n\n",
    "            avg_scores['default']['precision'] += precision / n\n",
    "            avg_scores['default']['recall'] += recall / n\n",
    "            avg_scores['default']['f1'] += f1_score(precision / n, recall / n)\n",
    "        else:\n",
    "            if mode != \"nb\":\n",
    "                y_pred = clf.predict(X_val)\n",
    "            else:\n",
    "                y_pred = clf.predict(X_val.multiply(r))\n",
    "\n",
    "            # Default scores\n",
    "            scores = get_scores(y_val, y_pred)\n",
    "            avg_scores['default']['accuracy'] += scores['accuracy']\n",
    "            avg_scores['default']['precision'] += scores['precision']\n",
    "            avg_scores['default']['recall'] += scores['recall']\n",
    "            avg_scores['default']['f1'] += scores['f1']\n",
    "\n",
    "        # Custom mode\n",
    "        if mode == \"dt\":\n",
    "            # Get new Decision Tree\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-1], custom_train_df.iloc[:, -1])\n",
    "        elif mode == \"lr\":\n",
    "            # Get new Logistic Regressor\n",
    "            clf = LogisticRegression(random_state=0, max_iter=2500)\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-1], custom_train_df.iloc[:, -1])\n",
    "        elif mode == \"nb\":\n",
    "            # Get new Naive Bayes (Logistic Regression)\n",
    "            clf, r = naive_bayes_support_vector_machine(custom_train_df.iloc[:, :-1], custom_train_df.iloc[:, -1])\n",
    "        elif mode == \"rf\":\n",
    "            clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-1], custom_train_df.iloc[:, -1])\n",
    "        elif mode == \"dl\":\n",
    "            print(f\"Training custom model {i + 1}/{n_iter}      \", end=\"\\r\")\n",
    "            # Get new DL\n",
    "            clf = run_spz_custom(custom_train_df)\n",
    "\n",
    "        # Get ground truth and predictions to measure performance\n",
    "        X_val, y_val = custom_validation_df.iloc[:, :-1], custom_validation_df.iloc[:, -1]\n",
    "        if mode == \"dl\":\n",
    "            accuracy = 0\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            n = 100\n",
    "            for _ in range(n):\n",
    "                _, acc, prc, rec = clf.evaluate(x=X_val, y=y_val, verbose=0)\n",
    "                accuracy += acc\n",
    "                precision += prc\n",
    "                recall += rec\n",
    "            avg_scores['custom']['accuracy'] += accuracy / n\n",
    "            avg_scores['custom']['precision'] += precision / n\n",
    "            avg_scores['custom']['recall'] += recall / n\n",
    "            avg_scores['custom']['f1'] += f1_score(precision / n, recall / n)\n",
    "        else:\n",
    "            if mode != \"nb\":\n",
    "                y_pred = clf.predict(X_val)\n",
    "            else:\n",
    "                y_pred = clf.predict(X_val.multiply(r))\n",
    "            # Custom scores\n",
    "            scores = get_scores(y_val, y_pred)\n",
    "            avg_scores['custom']['accuracy'] += scores['accuracy']\n",
    "            avg_scores['custom']['precision'] += scores['precision']\n",
    "            avg_scores['custom']['recall'] += scores['recall']\n",
    "            avg_scores['custom']['f1'] += scores['f1']\n",
    "\n",
    "        print(f\"{i + 1}/{n_iter}                            \", end=\"\\r\")\n",
    "\n",
    "    # Averaging\n",
    "    for t in avg_scores.keys():\n",
    "        for s in avg_scores[t].keys():\n",
    "            avg_scores[t][s] /= n_iter\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "    print(\"Accuracy - Default {:.3f}; Custom {:.3f}\".format(avg_scores['default']['accuracy'],\n",
    "                                                            avg_scores['custom']['accuracy']))\n",
    "    print(\"Precision - Default {:.3f}; Custom {:.3f}\".format(avg_scores['default']['precision'],\n",
    "                                                             avg_scores['custom']['precision']))\n",
    "    print(\"Recall - Default {:.3f}; Custom {:.3f}\".format(avg_scores['default']['recall'],\n",
    "                                                            avg_scores['custom']['recall']))\n",
    "    print(\"F1 - Default {:.3f}; Custom {:.3f}\".format(avg_scores['default']['f1'],\n",
    "                                                            avg_scores['custom']['f1']))\n",
    "    print(\"=============================\")\n",
    "    return #avg_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate impact upon removing single-attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact (bad/good) on performance is also evaluated from 1 (very small) to 5 (very big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nmedia', 'biol', 'url', 'nfollowing', 'nfollower', 'mediaLikeNumbers',\n",
      "       'mediaHashtagNumbers', 'followerToFollowing', 'hasMedia',\n",
      "       'userHasHighlighReels', 'usernameLength', 'usernameDigitCount', 'fake'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.from_dict(fake).columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nmedia (keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.907\n",
      "Precision - Default 0.908; Custom 0.908\n",
      "Recall - Default 0.907; Custom 0.906\n",
      "F1 - Default 0.907; Custom 0.907\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.924; Custom 0.922\n",
      "Precision - Default 0.940; Custom 0.942\n",
      "Recall - Default 0.907; Custom 0.900\n",
      "F1 - Default 0.923; Custom 0.920\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9243080568720435,\n",
       "  'precision': 0.9397988307100177,\n",
       "  'recall': 0.9069763033175329,\n",
       "  'f1': 0.9229456538509285},\n",
       " 'custom': {'accuracy': 0.921815165876782,\n",
       "  'precision': 0.9416056549228493,\n",
       "  'recall': 0.8996872037914648,\n",
       "  'f1': 0.9199956882724569}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['nmedia'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['nmedia'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['nmedia'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['nmedia'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['nmedia'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### biol (keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.899\n",
      "Precision - Default 0.908; Custom 0.899\n",
      "Recall - Default 0.908; Custom 0.901\n",
      "F1 - Default 0.907; Custom 0.899\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.924; Custom 0.918\n",
      "Precision - Default 0.939; Custom 0.943\n",
      "Recall - Default 0.907; Custom 0.890\n",
      "F1 - Default 0.923; Custom 0.915\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9239194312796265,\n",
       "  'precision': 0.939120851129531,\n",
       "  'recall': 0.9068720379146892,\n",
       "  'f1': 0.9225674046179021},\n",
       " 'custom': {'accuracy': 0.9178815165876797,\n",
       "  'precision': 0.9431410454327989,\n",
       "  'recall': 0.8896492890995211,\n",
       "  'f1': 0.9154274776943455}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['biol'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['biol'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['biol'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['biol'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['biol'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### url (drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.907\n",
      "Precision - Default 0.908; Custom 0.908\n",
      "Recall - Default 0.907; Custom 0.907\n",
      "F1 - Default 0.907; Custom 0.907\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.925; Custom 0.921\n",
      "Precision - Default 0.939; Custom 0.941\n",
      "Recall - Default 0.909; Custom 0.898\n",
      "F1 - Default 0.924; Custom 0.919\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.924890995260668,\n",
       "  'precision': 0.9391887565515636,\n",
       "  'recall': 0.9089289099526032,\n",
       "  'f1': 0.9236532486408021},\n",
       " 'custom': {'accuracy': 0.9209383886255956,\n",
       "  'precision': 0.941131471429088,\n",
       "  'recall': 0.8983412322274829,\n",
       "  'f1': 0.9190725368017605}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['url'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['url'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['url'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['url'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['url'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nfollowing (try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.906\n",
      "Precision - Default 0.907; Custom 0.906\n",
      "Recall - Default 0.908; Custom 0.908\n",
      "F1 - Default 0.907; Custom 0.906\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.925; Custom 0.910\n",
      "Precision - Default 0.939; Custom 0.932\n",
      "Recall - Default 0.909; Custom 0.884\n",
      "F1 - Default 0.924; Custom 0.907\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9249004739336543,\n",
       "  'precision': 0.9391661731593075,\n",
       "  'recall': 0.9089194312796186,\n",
       "  'f1': 0.9236487164524075},\n",
       " 'custom': {'accuracy': 0.9096255924170576,\n",
       "  'precision': 0.9320410626093761,\n",
       "  'recall': 0.8840189573459662,\n",
       "  'f1': 0.9071909033168793}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['nfollowing'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['nfollowing'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['nfollowing'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['nfollowing'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['nfollowing'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nfollower (try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.907\n",
      "Precision - Default 0.907; Custom 0.910\n",
      "Recall - Default 0.909; Custom 0.903\n",
      "F1 - Default 0.908; Custom 0.906\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.925; Custom 0.921\n",
      "Precision - Default 0.940; Custom 0.934\n",
      "Recall - Default 0.909; Custom 0.906\n",
      "F1 - Default 0.924; Custom 0.920\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9250568720379199,\n",
       "  'precision': 0.9397678421324944,\n",
       "  'recall': 0.9086350710900447,\n",
       "  'f1': 0.9237760803341596},\n",
       " 'custom': {'accuracy': 0.9209336492891036,\n",
       "  'precision': 0.9341237188838657,\n",
       "  'recall': 0.9060568720379116,\n",
       "  'f1': 0.9196987050382633}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['nfollower'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['nfollower'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['nfollower'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['nfollower'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['nfollower'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mediaLikeNumbers (drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.906; Custom 0.909\n",
      "Precision - Default 0.907; Custom 0.908\n",
      "Recall - Default 0.906; Custom 0.910\n",
      "F1 - Default 0.906; Custom 0.909\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.925; Custom 0.925\n",
      "Precision - Default 0.941; Custom 0.942\n",
      "Recall - Default 0.908; Custom 0.905\n",
      "F1 - Default 0.924; Custom 0.923\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9251279620853143,\n",
       "  'precision': 0.9406578640037537,\n",
       "  'recall': 0.9077914691943099,\n",
       "  'f1': 0.9237723148832673},\n",
       " 'custom': {'accuracy': 0.9245355450237023,\n",
       "  'precision': 0.9422991244031071,\n",
       "  'recall': 0.9047109004739317,\n",
       "  'f1': 0.9229564958208265}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['mediaLikeNumbers'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['mediaLikeNumbers'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['mediaLikeNumbers'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['mediaLikeNumbers'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['mediaLikeNumbers'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mediaHashtagNumbers (keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.906; Custom 0.901\n",
      "Precision - Default 0.906; Custom 0.901\n",
      "Recall - Default 0.907; Custom 0.902\n",
      "F1 - Default 0.906; Custom 0.901\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.924; Custom 0.916\n",
      "Precision - Default 0.939; Custom 0.939\n",
      "Recall - Default 0.908; Custom 0.889\n",
      "F1 - Default 0.923; Custom 0.913\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9244123222748862,\n",
       "  'precision': 0.9389795752089016,\n",
       "  'recall': 0.9080947867298556,\n",
       "  'f1': 0.9231174385378533},\n",
       " 'custom': {'accuracy': 0.9155213270142183,\n",
       "  'precision': 0.9387357781608782,\n",
       "  'recall': 0.8894123222748767,\n",
       "  'f1': 0.9132011073098545}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['mediaHashtagNumbers'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['mediaHashtagNumbers'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['mediaHashtagNumbers'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['mediaHashtagNumbers'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['mediaHashtagNumbers'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### followerToFollowing (keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.898\n",
      "Precision - Default 0.907; Custom 0.899\n",
      "Recall - Default 0.907; Custom 0.897\n",
      "F1 - Default 0.907; Custom 0.898\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.925; Custom 0.921\n",
      "Precision - Default 0.939; Custom 0.940\n",
      "Recall - Default 0.908; Custom 0.900\n",
      "F1 - Default 0.923; Custom 0.919\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9245023696682508,\n",
       "  'precision': 0.9391227980083509,\n",
       "  'recall': 0.9081611374407548,\n",
       "  'f1': 0.9232228937043447},\n",
       " 'custom': {'accuracy': 0.9209763033175385,\n",
       "  'precision': 0.9398910770710244,\n",
       "  'recall': 0.8997914691943087,\n",
       "  'f1': 0.9192322053885508}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['followerToFollowing'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['followerToFollowing'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['followerToFollowing'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['followerToFollowing'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['followerToFollowing'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hasMedia (try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.907\n",
      "Precision - Default 0.906; Custom 0.906\n",
      "Recall - Default 0.909; Custom 0.909\n",
      "F1 - Default 0.907; Custom 0.907\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.924; Custom 0.921\n",
      "Precision - Default 0.938; Custom 0.942\n",
      "Recall - Default 0.909; Custom 0.898\n",
      "F1 - Default 0.923; Custom 0.919\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9242985781990571,\n",
       "  'precision': 0.9380340296188371,\n",
       "  'recall': 0.9089004739336473,\n",
       "  'f1': 0.9230730221678884},\n",
       " 'custom': {'accuracy': 0.921061611374411,\n",
       "  'precision': 0.941518092409157,\n",
       "  'recall': 0.8981990521326977,\n",
       "  'f1': 0.9191524580168394}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['hasMedia'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['hasMedia'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['hasMedia'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['hasMedia'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['hasMedia'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### userHasHighlighReels (try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.908\n",
      "Precision - Default 0.908; Custom 0.908\n",
      "Recall - Default 0.907; Custom 0.908\n",
      "F1 - Default 0.907; Custom 0.908\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.925; Custom 0.921\n",
      "Precision - Default 0.940; Custom 0.944\n",
      "Recall - Default 0.908; Custom 0.897\n",
      "F1 - Default 0.923; Custom 0.919\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9246919431279671,\n",
       "  'precision': 0.939924420294778,\n",
       "  'recall': 0.9076777251184802,\n",
       "  'f1': 0.9233673803320884},\n",
       " 'custom': {'accuracy': 0.9214312796208564,\n",
       "  'precision': 0.9435167909745227,\n",
       "  'recall': 0.8968246445497583,\n",
       "  'f1': 0.9194069726035731}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['userHasHighlighReels'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['userHasHighlighReels'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['userHasHighlighReels'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['userHasHighlighReels'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['userHasHighlighReels'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usernameLength (drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.910\n",
      "Precision - Default 0.907; Custom 0.910\n",
      "Recall - Default 0.907; Custom 0.912\n",
      "F1 - Default 0.907; Custom 0.911\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.925; Custom 0.921\n",
      "Precision - Default 0.940; Custom 0.942\n",
      "Recall - Default 0.908; Custom 0.898\n",
      "F1 - Default 0.923; Custom 0.919\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9247156398104317,\n",
       "  'precision': 0.9398588586530856,\n",
       "  'recall': 0.9078009478672957,\n",
       "  'f1': 0.9233844016380491},\n",
       " 'custom': {'accuracy': 0.9210379146919462,\n",
       "  'precision': 0.942017525284914,\n",
       "  'recall': 0.8975829383886216,\n",
       "  'f1': 0.9190857764516015}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['usernameLength'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['usernameLength'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['usernameLength'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['usernameLength'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['usernameLength'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usernameDigitCount (drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Decision Trees over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.907; Custom 0.908\n",
      "Precision - Default 0.907; Custom 0.908\n",
      "Recall - Default 0.907; Custom 0.909\n",
      "F1 - Default 0.907; Custom 0.908\n",
      "=============================\n",
      "Calculating metrics for Random Forests over 500 times\n",
      "Done!00                            \n",
      "Accuracy - Default 0.924; Custom 0.921\n",
      "Precision - Default 0.939; Custom 0.942\n",
      "Recall - Default 0.907; Custom 0.898\n",
      "F1 - Default 0.922; Custom 0.919\n",
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default': {'accuracy': 0.9238246445497681,\n",
       "  'precision': 0.9389156413922014,\n",
       "  'recall': 0.9068909952606594,\n",
       "  'f1': 0.9224792819321779},\n",
       " 'custom': {'accuracy': 0.9212369668246478,\n",
       "  'precision': 0.9416549483670255,\n",
       "  'recall': 0.898407582938383,\n",
       "  'f1': 0.9193520469604484}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(fake, correct, ['usernameDigitCount'], \"dt\", N_EXP)   # DecisionTree\n",
    "experiment(fake, correct, ['usernameDigitCount'], \"rf\", N_EXP)   # RandomForest\n",
    "#experiment(fake, correct, ['usernameDigitCount'], \"lr\", N_EXP)   # LogisticRegressor\n",
    "#experiment(fake, correct, ['usernameDigitCount'], \"nb\", N_EXP)   # NaiveBayes (with lr inside)\n",
    "#experiment(fake, correct, ['usernameDigitCount'], \"dl\", N_EXP)   # NeuralNetwork"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Fake Account Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 16:52:30.611649: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 16:52:30.764341: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-28 16:52:30.764371: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-28 16:52:31.436572: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-28 16:52:31.436656: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-28 16:52:31.436665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from dataset.normalizer import json_importer_full, csv_importer_full\n",
    "from dataset.utils import find_demarcator\n",
    "from utils.utils import experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `Instagram Fake and Automated Account Detection` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading from file ./dataset/sources/automatedAccountData.json...\n",
      "Loaded 700 entries from source ./dataset/sources/automatedAccountData.json\n",
      "Now loading from file ./dataset/sources/nonautomatedAccountData.json...\n",
      "Loaded 700 entries from source ./dataset/sources/nonautomatedAccountData.json\n",
      "Now loading from file ./dataset/sources/user_fake_authentic_2class.csv...\n",
      "Loaded 65327 entries from source ./dataset/sources/user_fake_authentic_2class.csv\n"
     ]
    }
   ],
   "source": [
    "fake_spz = json_importer_full(\"./dataset/sources/automatedAccountData.json\", True)\n",
    "correct_spz = json_importer_full(\"./dataset/sources/nonautomatedAccountData.json\", False)\n",
    "default_dataset = csv_importer_full(\"./dataset/sources/user_fake_authentic_2class.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `IJECE` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_demarcator(default_dataset)\n",
    "fake_IJECE = default_dataset[:idx]\n",
    "correct_IJECE = default_dataset[idx:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dt - Decision Tree\n",
    "- lr - Linear Regression\n",
    "- nb - Naive Bayes\n",
    "- rf - Random Forest\n",
    "- dl - Percettrone Multistrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running test on dataset 'Instagram Fake and Automated Account Detection' (internal name: 'spz')...\n",
      "Calculating metrics for Random Forests over 50 times\n",
      "Done!                            \n",
      "Accuracy - Default 0.923; Custom 0.913\n",
      "Precision - Default 0.943; Custom 0.937\n",
      "Recall - Default 0.900; Custom 0.886\n",
      "F1 - Default 0.921; Custom 0.911\n",
      "=============================\n",
      "Running test on dataset 'IJECE' (internal name: 'IJECE')...\n",
      "Calculating metrics for Random Forests over 50 times\n",
      "Done!                            \n",
      "Accuracy - Default 0.857; Custom 0.865\n",
      "Precision - Default 0.929; Custom 0.971\n",
      "Recall - Default 0.775; Custom 0.754\n",
      "F1 - Default 0.845; Custom 0.849\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "exp = \"rf\"\n",
    "n_iter = 50\n",
    "\n",
    "results = {\"spz\": dict(), \"IJECE\": dict()}\n",
    "\n",
    "print(\"\\nRunning test on dataset 'Instagram Fake and Automated Account Detection' (internal name: 'spz')...\")\n",
    "res = experiment(fake_spz, correct_spz, csv=False, mode=exp, n_iter=n_iter)\n",
    "results[\"spz\"][exp] = res\n",
    "\n",
    "print(\"Running test on dataset 'IJECE' (internal name: 'IJECE')...\")\n",
    "res = experiment(fake_IJECE, correct_IJECE, csv=True, mode=exp, n_iter=n_iter)\n",
    "results[\"IJECE\"][exp] = res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.normalizer import csv_importer_full\n",
    "from dataset.utils import find_demarcator, shuffle_and_split\n",
    "from sequoia_comparison.utils import get_scores\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dataset = csv_importer_full(\"dataset/sources/user_fake_authentic_2class.csv\")\n",
    "idx = find_demarcator(default_dataset)\n",
    "\n",
    "fake = default_dataset[:idx]\n",
    "correct = default_dataset[idx:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 26 - 04"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXP = 100 # Number of experiments\n",
    "MAX_ITER = 50000 # Maximum number of iterations for LR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using custom experiment functions not to mess up with the real experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Drop target columns from dataset\n",
    "'''\n",
    "def get_custom_dataset(train_df, validation_df, column_names=[]):\n",
    "    custom_train_df = train_df.drop(column_names, axis=1)\n",
    "    custom_validation_df = validation_df.drop(column_names, axis=1)\n",
    "\n",
    "    return custom_train_df, custom_validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "column_names: list of columns to drop from default dataset to get custom dataset\n",
    "\n",
    "modes:\n",
    " - \"dt\" => DecisionTree\n",
    " - \"lr\" => LogisticRegression\n",
    "'''\n",
    "def experiment(fake, correct, column_names=[], mode=\"dt\", n_iter=N_EXP):\n",
    "    avg_scores = {\n",
    "        'default': {'precision': 0, 'accuracy': 0},\n",
    "        'custom': {'precision': 0, 'accuracy': 0}\n",
    "    }\n",
    "\n",
    "    if mode == \"dt\":\n",
    "        print(f\"Calculating precision and accuracy metrics for Decision Trees over {n_iter} times\")\n",
    "    elif mode == \"lr\":\n",
    "        print(f\"Calculating precision and accuracy metrics for Logistic Regression (max_iter={MAX_ITER}) over {n_iter} times\")\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # Get new train_df and validation_df, same for default and custom\n",
    "        train_df, validation_df = shuffle_and_split(fake, correct)\n",
    "        custom_train_df, custom_validation_df = get_custom_dataset(train_df, validation_df, column_names)\n",
    "\n",
    "        # Default mode\n",
    "        if mode == \"dt\":\n",
    "            # Get new Decision Tree\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf = clf.fit(train_df.iloc[:, :-2], train_df.iloc[:, -1])\n",
    "        elif mode == \"lr\":\n",
    "            # Get new Logistic Regressor\n",
    "            clf = LogisticRegression(random_state=0, max_iter=MAX_ITER)\n",
    "            clf = clf.fit(train_df.iloc[:, :-2], train_df.iloc[:, -1])\n",
    "\n",
    "        # Get ground truth and predictions to measure performance\n",
    "        X_val, y_val = validation_df.iloc[:, :-2], validation_df.iloc[:, -1]\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        # Default scores\n",
    "        scores = get_scores(y_val, y_pred)\n",
    "        avg_scores['default']['precision'] += scores['precision']\n",
    "        avg_scores['default']['accuracy'] += scores['accuracy']\n",
    "\n",
    "        # Custom mode\n",
    "        if mode == \"dt\":\n",
    "            # Get new Decision Tree\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-2], custom_train_df.iloc[:, -1])\n",
    "        elif mode == \"lr\":\n",
    "            # Get new Logistic Regressor\n",
    "            clf = LogisticRegression(random_state=0, max_iter=2500)\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-2], custom_train_df.iloc[:, -1])\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "        # Get ground truth and predictions to measure performance\n",
    "        X_val, y_val = custom_validation_df.iloc[:, :-2], custom_validation_df.iloc[:, -1]\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        # Custom scores\n",
    "        scores = get_scores(y_val, y_pred)\n",
    "        avg_scores['custom']['precision'] += scores['precision']\n",
    "        avg_scores['custom']['accuracy'] += scores['accuracy']\n",
    "\n",
    "        #print(f\"{i + 1}/{n_iter}\", end=\"\\r\")\n",
    "\n",
    "    # Averaging\n",
    "    for t in avg_scores.keys():\n",
    "        for s in avg_scores[t].keys():\n",
    "            avg_scores[t][s] /= n_iter\n",
    "\n",
    "    print('Done!\\n\\n')\n",
    "\n",
    "    print('default avg precision:', \"{:.5f}\".format(avg_scores['default']['precision']))\n",
    "    print('default avg accuracy:', \"{:.5f}\".format(avg_scores['default']['accuracy']))\n",
    "\n",
    "    print('custom avg precision:', \"{:.5f}\".format(avg_scores['custom']['precision']))\n",
    "    print('custom avg accuracy:', \"{:.5f}\".format(avg_scores['custom']['accuracy']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate impact upon removing single-attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact (bad/good) on performance is also evaluated from 1 (very small) to 5 (very big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(fake).columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nmedia - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['nmedia'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['nmedia'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85094\n",
    "# default avg accuracy: 0.85395\n",
    "# custom avg precision: 0.84954\n",
    "# custom avg accuracy: 0.85216\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.81017\n",
    "# default avg accuracy: 0.79699\n",
    "# custom avg precision: 0.80927\n",
    "# custom avg accuracy: 0.79603"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing nmedia has a bad impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flw - K (C - LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['flw'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['flw'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85141\n",
    "# default avg accuracy: 0.85402\n",
    "# custom avg precision: 0.83480\n",
    "# custom avg accuracy: 0.83765\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80972\n",
    "# default avg accuracy: 0.79626\n",
    "# custom avg precision: 0.80990\n",
    "# custom avg accuracy: 0.79693"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flw has a bad impact on performace on DT, but positive on LR - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flg - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['flg'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['flg'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85214\n",
    "# default avg accuracy: 0.85457\n",
    "# custom avg precision: 0.80051\n",
    "# custom avg accuracy: 0.80298\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80903\n",
    "# default avg accuracy: 0.79640\n",
    "# custom avg precision: 0.74349\n",
    "# custom avg accuracy: 0.74912"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flg has a bad impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### biol - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['biol'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['biol'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85076\n",
    "# default avg accuracy: 0.85367\n",
    "# custom avg precision: 0.84963\n",
    "# custom avg accuracy: 0.85216\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80935\n",
    "# default avg accuracy: 0.79646\n",
    "# custom avg precision: 0.80896\n",
    "# custom avg accuracy: 0.79454"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing biol has a bad impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pic - D (C - DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['pic'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['pic'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85159\n",
    "# default avg accuracy: 0.85417\n",
    "# custom avg precision: 0.85190\n",
    "# custom avg accuracy: 0.85439\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80914\n",
    "# default avg accuracy: 0.79591\n",
    "# custom avg precision: 0.80716\n",
    "# custom avg accuracy: 0.79518"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing pic has a positive impact on performances on DT, but bad on LR - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### url - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['url'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['url'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85121\n",
    "# default avg accuracy: 0.85404\n",
    "# custom avg precision: 0.80325\n",
    "# custom avg accuracy: 0.80367\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80994\n",
    "# default avg accuracy: 0.79702\n",
    "# custom avg precision: 0.78941\n",
    "# custom avg accuracy: 0.76510"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing url has a bad impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cl - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cl'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['cl'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85147\n",
    "# default avg accuracy: 0.85408\n",
    "# custom avg precision: 0.85019\n",
    "# custom avg accuracy: 0.85321\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80894\n",
    "# default avg accuracy: 0.79608\n",
    "# custom avg precision: 0.80742\n",
    "# custom avg accuracy: 0.79552"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cl has a BAD impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cz - D (C - LR/BOTH?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cz'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['cz'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85135\n",
    "# default avg accuracy: 0.85380\n",
    "# custom avg precision: 0.85122\n",
    "# custom avg accuracy: 0.85381\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80933\n",
    "# default avg accuracy: 0.79641\n",
    "# custom avg precision: 0.81296\n",
    "# custom avg accuracy: 0.79740"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cz has a bad (?) impact on performace on DT, but positive on LR - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ni - K (C - LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['ni'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['ni'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85114\n",
    "# default avg accuracy: 0.85380\n",
    "# custom avg precision: 0.85048\n",
    "# custom avg accuracy: 0.85331\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80995\n",
    "# default avg accuracy: 0.79680\n",
    "# custom avg precision: 0.81205\n",
    "# custom avg accuracy: 0.79769"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing ni has a bad impact on performance on DT, but positive on LR - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### erl - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['erl'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['erl'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85144\n",
    "# default avg accuracy: 0.85371\n",
    "# custom avg precision: 0.83524\n",
    "# custom avg accuracy: 0.83825\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80988\n",
    "# default avg accuracy: 0.79642\n",
    "# custom avg precision: 0.80894\n",
    "# custom avg accuracy: 0.79603"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing erl has a bad impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### erc - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['erc'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['erc'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85207\n",
    "# default avg accuracy: 0.85432\n",
    "# custom avg precision: 0.82484\n",
    "# custom avg accuracy: 0.82632\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80992\n",
    "# default avg accuracy: 0.79728\n",
    "# custom avg precision: 0.80638\n",
    "# custom avg accuracy: 0.79195"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing erc has a bad impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lt - D (C - DT/BOTH?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['lt'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['lt'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85129\n",
    "# default avg accuracy: 0.85399\n",
    "# custom avg precision: 0.85167\n",
    "# custom avg accuracy: 0.85433\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80996\n",
    "# default avg accuracy: 0.79657\n",
    "# custom avg precision: 0.81144\n",
    "# custom avg accuracy: 0.78659"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing lt has a positive impact on performace on DT, but bad (?) on LR - CONSIDER DROPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ahc - D (C - DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['ahc'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['ahc'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85075\n",
    "# default avg accuracy: 0.85389\n",
    "# custom avg precision: 0.85124\n",
    "# custom avg accuracy: 0.85410\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80897\n",
    "# default avg accuracy: 0.79657\n",
    "# custom avg precision: 0.80818\n",
    "# custom avg accuracy: 0.79578"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing ahc has a positive impact on performace on DT, but bad on LR - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pr - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['pr'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['pr'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85152\n",
    "# default avg accuracy: 0.85438\n",
    "# custom avg precision: 0.84928\n",
    "# custom avg accuracy: 0.85233\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.81019\n",
    "# default avg accuracy: 0.79716\n",
    "# custom avg precision: 0.80676\n",
    "# custom avg accuracy: 0.79327"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing pr has a bad impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fo - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['fo'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['fo'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85148\n",
    "# default avg accuracy: 0.85402\n",
    "# custom avg precision: 0.85037\n",
    "# custom avg accuracy: 0.85301\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80995\n",
    "# default avg accuracy: 0.79711\n",
    "# custom avg precision: 0.80904\n",
    "# custom avg accuracy: 0.79569"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing fo has a bad impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cs - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cs'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['cs'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85115\n",
    "# default avg accuracy: 0.85405\n",
    "# custom avg precision: 0.85046\n",
    "# custom avg accuracy: 0.85358\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80959\n",
    "# default avg accuracy: 0.79664\n",
    "# custom avg precision: 0.78385\n",
    "# custom avg accuracy: 0.78669"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cs has a small bad impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avgtime - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['avgtime'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['avgtime'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85115\n",
    "# default avg accuracy: 0.85387\n",
    "# custom avg precision: 0.85046\n",
    "# custom avg accuracy: 0.85337\n",
    "# Calculating precision and accuracy metrics for Logistic Regression (max_iter=25000) over 100 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80965\n",
    "# default avg accuracy: 0.79644\n",
    "# custom avg precision: 0.78246\n",
    "# custom avg accuracy: 0.78587"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flw has a positive impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second experiment with custom features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we fit (several) Decision Tree Classifier(s) (and Linear Regressors) removing from dataframes the attributes which seemed to worsen performance during the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, [\"flw\", \"cz\", \"pic\", \"ni\", \"lt\", \"ahc\"], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, [\"flw\", \"pic\", \"cz\", \"ni\", \"lt\", \"ahc\"], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85170\n",
    "# default avg accuracy: 0.85395\n",
    "# custom avg precision: 0.83050\n",
    "# custom avg accuracy: 0.83394\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80960\n",
    "# default avg accuracy: 0.79711\n",
    "# custom avg precision: 0.78490\n",
    "# custom avg accuracy: 0.75939"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONLUSION: IT FAILED !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we fit (several) Decision Tree Classifier(s) (and Linear Regressors) removing from dataframes the attributes which seemed to worsen performance (of Decision Trees only ! ) during the experiments.\n",
    "\n",
    "(HT: LR depends a lot more on MAX_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, [\"pic\", \"cz\", \"lt\", \"ahc\"], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, [\"pic\", \"cz\", \"lt\", \"ahc\"], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85070\n",
    "# default avg accuracy: 0.85364\n",
    "# custom avg precision: 0.85122\n",
    "# custom avg accuracy: 0.85394\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80923\n",
    "# default avg accuracy: 0.79600\n",
    "# custom avg precision: 0.77695\n",
    "# custom avg accuracy: 0.76550"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSIONS: removing ni, lt, ahc and avgtime improved DT but worsened LR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

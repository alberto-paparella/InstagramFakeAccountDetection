{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Fake Account Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.normalizer import csv_importer_full\n",
    "from dataset.utils import find_demarcator, shuffle_and_split\n",
    "from sequoia_comparison.utils import get_scores\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading from file dataset/sources/user_fake_authentic_2class.csv...\n",
      "Loaded 65327 entries from source dataset/sources/user_fake_authentic_2class.csv\n"
     ]
    }
   ],
   "source": [
    "default_dataset = csv_importer_full(\"dataset/sources/user_fake_authentic_2class.csv\")\n",
    "idx = find_demarcator(default_dataset)\n",
    "\n",
    "fake = default_dataset[:idx]\n",
    "correct = default_dataset[idx:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 26 - 04"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using custom experiment functions not to mess up with the real experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Drop target columns from dataset\n",
    "'''\n",
    "def get_custom_dataset(train_df, validation_df, column_names=[]):\n",
    "    custom_train_df = train_df.drop(column_names, axis=1)\n",
    "    custom_validation_df = validation_df.drop(column_names, axis=1)\n",
    "\n",
    "    return custom_train_df, custom_validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "column_names: list of columns to drop from default dataset to get custom dataset\n",
    "\n",
    "modes:\n",
    " - \"dt\" => DecisionTree\n",
    " - \"lr\" => LogisticRegression\n",
    "'''\n",
    "def experiment(fake, correct, column_names=[], mode=\"dt\", n_iter=20):\n",
    "    avg_scores = {\n",
    "        'default': {'precision': 0, 'accuracy': 0},\n",
    "        'custom': {'precision': 0, 'accuracy': 0}\n",
    "    }\n",
    "\n",
    "    if mode == \"dt\":\n",
    "        print(f\"Calculating precision and accuracy metrics for Decision Trees over {n_iter} times\")\n",
    "    elif mode == \"lr\":\n",
    "        print(f\"Calculating precision and accuracy metrics for Logistic Regression over {n_iter} times\")\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # Get new train_df and validation_df, same for default and custom\n",
    "        train_df, validation_df = shuffle_and_split(fake, correct)\n",
    "        custom_train_df, custom_validation_df = get_custom_dataset(train_df, validation_df, column_names)\n",
    "\n",
    "        # Default mode\n",
    "        if mode == \"dt\":\n",
    "            # Get new Decision Tree\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf = clf.fit(train_df.iloc[:, :-2], train_df.iloc[:, -1])\n",
    "        elif mode == \"lr\":\n",
    "            # Get new Logistic Regressor\n",
    "            clf = LogisticRegression(random_state=0, max_iter=10000)\n",
    "            clf = clf.fit(train_df.iloc[:, :-2], train_df.iloc[:, -1])\n",
    "\n",
    "        # Get ground truth and predictions to measure performance\n",
    "        X_val, y_val = validation_df.iloc[:, :-2], validation_df.iloc[:, -1]\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        # Default scores\n",
    "        scores = get_scores(y_val, y_pred)\n",
    "        avg_scores['default']['precision'] += scores['precision']\n",
    "        avg_scores['default']['accuracy'] += scores['accuracy']\n",
    "\n",
    "        # Custom mode\n",
    "        if mode == \"dt\":\n",
    "            # Get new Decision Tree\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-2], custom_train_df.iloc[:, -1])\n",
    "        elif mode == \"lr\":\n",
    "            # Get new Logistic Regressor\n",
    "            clf = LogisticRegression(random_state=0, max_iter=2500)\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-2], custom_train_df.iloc[:, -1])\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "        # Get ground truth and predictions to measure performance\n",
    "        X_val, y_val = custom_validation_df.iloc[:, :-2], custom_validation_df.iloc[:, -1]\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        # Custom scores\n",
    "        scores = get_scores(y_val, y_pred)\n",
    "        avg_scores['custom']['precision'] += scores['precision']\n",
    "        avg_scores['custom']['accuracy'] += scores['accuracy']\n",
    "\n",
    "        print(f\"{i + 1}/{n_iter}\", end=\"\\r\")\n",
    "\n",
    "    # Averaging\n",
    "    for t in avg_scores.keys():\n",
    "        for s in avg_scores[t].keys():\n",
    "            avg_scores[t][s] /= n_iter\n",
    "\n",
    "    print('Done!\\n\\n')\n",
    "\n",
    "    print('default avg precision:', \"{:.3f}\".format(avg_scores['default']['precision']))\n",
    "    print('default avg accuracy:', \"{:.3f}\".format(avg_scores['default']['accuracy']))\n",
    "\n",
    "    print('custom avg precision:', \"{:.3f}\".format(avg_scores['custom']['precision']))\n",
    "    print('custom avg accuracy:', \"{:.3f}\".format(avg_scores['custom']['accuracy']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate impact upon removing single-attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact (bad/good) on performance is also evaluated from 1 (very small) to 5 (very big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nmedia', 'flw', 'flg', 'biol', 'pic', 'url', 'cl', 'cz', 'ni', 'erl',\n",
      "       'erc', 'lt', 'ahc', 'pr', 'fo', 'cs', 'avgtime', 'fake'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.from_dict(fake).columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nmedia - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.850\n",
      "custom avg accuracy: 0.853\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.811\n",
      "default avg accuracy: 0.797\n",
      "custom avg precision: 0.811\n",
      "custom avg accuracy: 0.797\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['nmedia'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['nmedia'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.850\n",
    "# custom avg accuracy: 0.853\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.811\n",
    "# default avg accuracy: 0.797\n",
    "# custom avg precision: 0.811\n",
    "# custom avg accuracy: 0.797"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing nmedia has a bad (1) impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flw - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.850\n",
      "default avg accuracy: 0.853\n",
      "custom avg precision: 0.834\n",
      "custom avg accuracy: 0.837\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.809\n",
      "default avg accuracy: 0.797\n",
      "custom avg precision: 0.811\n",
      "custom avg accuracy: 0.798\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['flw'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['flw'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.850\n",
    "# default avg accuracy: 0.853\n",
    "# custom avg precision: 0.834\n",
    "# custom avg accuracy: 0.837\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.809\n",
    "# default avg accuracy: 0.797\n",
    "# custom avg precision: 0.811\n",
    "# custom avg accuracy: 0.798"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flw has a bad (3) impact on performace (on DT, but positive (1) on LR) - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flg - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.853\n",
      "custom avg precision: 0.800\n",
      "custom avg accuracy: 0.803\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.811\n",
      "default avg accuracy: 0.797\n",
      "custom avg precision: 0.745\n",
      "custom avg accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['flg'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['flg'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.853\n",
    "# custom avg precision: 0.800\n",
    "# custom avg accuracy: 0.803\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.811\n",
    "# default avg accuracy: 0.797\n",
    "# custom avg precision: 0.745\n",
    "# custom avg accuracy: 0.750"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flg has a bad (5) impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### biol - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.849\n",
      "custom avg accuracy: 0.852\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.810\n",
      "default avg accuracy: 0.798\n",
      "custom avg precision: 0.810\n",
      "custom avg accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['biol'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['biol'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.849\n",
    "# custom avg accuracy: 0.852\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.810\n",
    "# default avg accuracy: 0.798\n",
    "# custom avg precision: 0.810\n",
    "# custom avg accuracy: 0.795"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing biol has a bad (2) impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pic - D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.852\n",
      "custom avg accuracy: 0.854\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.809\n",
      "default avg accuracy: 0.796\n",
      "custom avg precision: 0.807\n",
      "custom avg accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['pic'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['pic'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.852\n",
    "# custom avg accuracy: 0.854\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.809\n",
    "# default avg accuracy: 0.796\n",
    "# custom avg precision: 0.807\n",
    "# custom avg accuracy: 0.795"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing pic has a positive (2) impact on performance (on DT, but bad (1) on LR) - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### url - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['url'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['url'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.852\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.803\n",
    "# custom avg accuracy: 0.804\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.807\n",
    "# default avg accuracy: 0.796\n",
    "# custom avg precision: 0.787\n",
    "# custom avg accuracy: 0.763"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing url has a bad (5) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cl - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.850\n",
      "default avg accuracy: 0.853\n",
      "custom avg precision: 0.849\n",
      "custom avg accuracy: 0.852\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.809\n",
      "default avg accuracy: 0.797\n",
      "custom avg precision: 0.809\n",
      "custom avg accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cl'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['cl'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.850\n",
    "# default avg accuracy: 0.853\n",
    "# custom avg precision: 0.849\n",
    "# custom avg accuracy: 0.852\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.809\n",
    "# default avg accuracy: 0.797\n",
    "# custom avg precision: 0.809\n",
    "# custom avg accuracy: 0.796"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cl has a BAD (2) impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cz - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.852\n",
      "default avg accuracy: 0.855\n",
      "custom avg precision: 0.851\n",
      "custom avg accuracy: 0.855\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.812\n",
      "default avg accuracy: 0.798\n",
      "custom avg precision: 0.815\n",
      "custom avg accuracy: 0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cz'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['cz'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.852\n",
    "# default avg accuracy: 0.855\n",
    "# custom avg precision: 0.851\n",
    "# custom avg accuracy: 0.855\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.812\n",
    "# default avg accuracy: 0.798\n",
    "# custom avg precision: 0.815\n",
    "# custom avg accuracy: 0.798"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cz has a bad (1) impact on performace (on DT, but positive (1) on LR) - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ni - D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.852\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.852\n",
      "custom avg accuracy: 0.854\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "8/20\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.811\n",
      "default avg accuracy: 0.796\n",
      "custom avg precision: 0.813\n",
      "custom avg accuracy: 0.798\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['ni'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['ni'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.852\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.852\n",
    "# custom avg accuracy: 0.854\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.811\n",
    "# default avg accuracy: 0.796\n",
    "# custom avg precision: 0.813\n",
    "# custom avg accuracy: 0.798"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing ni has a no impact on performance (on DT, but positive (1) on LR) - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### erl - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.853\n",
      "custom avg precision: 0.835\n",
      "custom avg accuracy: 0.838\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.808\n",
      "default avg accuracy: 0.795\n",
      "custom avg precision: 0.808\n",
      "custom avg accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['erl'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['erl'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.853\n",
    "# custom avg precision: 0.835\n",
    "# custom avg accuracy: 0.838\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.808\n",
    "# default avg accuracy: 0.795\n",
    "# custom avg precision: 0.808\n",
    "# custom avg accuracy: 0.795"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing erl has a bad (3) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### erc - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.850\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.824\n",
      "custom avg accuracy: 0.826\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.810\n",
      "default avg accuracy: 0.795\n",
      "custom avg precision: 0.806\n",
      "custom avg accuracy: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['erc'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['erc'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.850\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.824\n",
    "# custom avg accuracy: 0.826\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.810\n",
    "# default avg accuracy: 0.795\n",
    "# custom avg precision: 0.806\n",
    "# custom avg accuracy: 0.791"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing erc has a bad (3) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lt - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.853\n",
      "default avg accuracy: 0.855\n",
      "custom avg precision: 0.851\n",
      "custom avg accuracy: 0.854\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.810\n",
      "default avg accuracy: 0.796\n",
      "custom avg precision: 0.814\n",
      "custom avg accuracy: 0.787\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['lt'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['lt'], \"lr\", 20)   # LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing lt has a bad (1) impact on performace (on DT, but positive (1) on LR) - CONSIDER DROPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ahc - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.851\n",
      "custom avg accuracy: 0.854\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.808\n",
      "default avg accuracy: 0.795\n",
      "custom avg precision: 0.807\n",
      "custom avg accuracy: 0.794\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['ahc'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['ahc'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "#LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.851\n",
    "# custom avg accuracy: 0.854\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.808\n",
    "# default avg accuracy: 0.795\n",
    "# custom avg precision: 0.807\n",
    "# custom avg accuracy: 0.794"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing ahc has a no impact on performace (on DT, but bad (1) on LR) - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pr - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.849\n",
      "custom avg accuracy: 0.852\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.810\n",
      "default avg accuracy: 0.797\n",
      "custom avg precision: 0.806\n",
      "custom avg accuracy: 0.793\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['pr'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['pr'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.849\n",
    "# custom avg accuracy: 0.852\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.810\n",
    "# default avg accuracy: 0.797\n",
    "# custom avg precision: 0.806\n",
    "# custom avg accuracy: 0.793"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing pr has a bad (1) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fo - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.850\n",
      "custom avg accuracy: 0.853\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.809\n",
      "default avg accuracy: 0.797\n",
      "custom avg precision: 0.808\n",
      "custom avg accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['fo'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['fo'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.850\n",
    "# custom avg accuracy: 0.853\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.809\n",
    "# default avg accuracy: 0.797\n",
    "# custom avg precision: 0.808\n",
    "# custom avg accuracy: 0.795"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing fo has a bad (1) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cs - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.851\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.849\n",
      "custom avg accuracy: 0.853\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "2/20\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.811\n",
      "default avg accuracy: 0.797\n",
      "custom avg precision: 0.785\n",
      "custom avg accuracy: 0.788\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cs'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['cs'], \"lr\", 20)   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.849\n",
    "# custom avg accuracy: 0.853\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.811\n",
    "# default avg accuracy: 0.797\n",
    "# custom avg precision: 0.785\n",
    "# custom avg accuracy: 0.788"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cs has a small bad (2) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avgtime - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.852\n",
      "default avg accuracy: 0.854\n",
      "custom avg precision: 0.851\n",
      "custom avg accuracy: 0.853\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "14/20\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.809\n",
      "default avg accuracy: 0.797\n",
      "custom avg precision: 0.784\n",
      "custom avg accuracy: 0.788\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['avgtime'], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, ['avgtime'], \"lr\", 20)   # LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flw has a bad (2) impact on performace - KEEP IT !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second experiment with custom features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we fit (several) Decision Tree Classifier(s) (and Linear Regressors) removing from dataframes the attributes which seemed to worsen performance during the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.852\n",
      "default avg accuracy: 0.855\n",
      "custom avg precision: 0.850\n",
      "custom avg accuracy: 0.854\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
      "1/20\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Experiments\u001b[39;00m\n\u001b[1;32m      2\u001b[0m experiment(fake, correct, [\u001b[39m\"\u001b[39m\u001b[39mpic\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mni\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mdt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m20\u001b[39m)   \u001b[39m# DecisionTree\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m experiment(fake, correct, [\u001b[39m\"\u001b[39;49m\u001b[39mpic\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mni\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m20\u001b[39;49m)   \u001b[39m# LogisticRegression\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 34\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(fake, correct, column_names, mode, n_iter)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[39m# Get new Logistic Regressor\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     clf \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mfit(train_df\u001b[39m.\u001b[39;49miloc[:, :\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m], train_df\u001b[39m.\u001b[39;49miloc[:, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     36\u001b[0m \u001b[39m# Get ground truth and predictions to measure performance\u001b[39;00m\n\u001b[1;32m     37\u001b[0m X_val, y_val \u001b[39m=\u001b[39m validation_df\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], validation_df\u001b[39m.\u001b[39miloc[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1289\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1291\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[1;32m   1292\u001b[0m     path_func(\n\u001b[1;32m   1293\u001b[0m         X,\n\u001b[1;32m   1294\u001b[0m         y,\n\u001b[1;32m   1295\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1296\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1297\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1298\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1299\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1300\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1301\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1302\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1303\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1304\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1305\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1306\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1307\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1308\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1309\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1310\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1311\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m   1312\u001b[0m     )\n\u001b[1;32m   1313\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1314\u001b[0m )\n\u001b[1;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:450\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    446\u001b[0m l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C\n\u001b[1;32m    447\u001b[0m iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[1;32m    448\u001b[0m     np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)\n\u001b[1;32m    449\u001b[0m ]\n\u001b[0;32m--> 450\u001b[0m opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m    451\u001b[0m     func,\n\u001b[1;32m    452\u001b[0m     w0,\n\u001b[1;32m    453\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    454\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    455\u001b[0m     args\u001b[39m=\u001b[39;49m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    456\u001b[0m     options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint, \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: tol, \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_iter},\n\u001b[1;32m    457\u001b[0m )\n\u001b[1;32m    458\u001b[0m n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    459\u001b[0m     solver,\n\u001b[1;32m    460\u001b[0m     opt_res,\n\u001b[1;32m    461\u001b[0m     max_iter,\n\u001b[1;32m    462\u001b[0m     extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    463\u001b[0m )\n\u001b[1;32m    464\u001b[0m w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_minimize.py:681\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    679\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    680\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 681\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    682\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    683\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    684\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    685\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    356\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    363\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_linear_loss.py:291\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    289\u001b[0m     grad[:n_features] \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m grad_pointwise \u001b[39m+\u001b[39m l2_reg_strength \u001b[39m*\u001b[39m weights\n\u001b[1;32m    290\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 291\u001b[0m         grad[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m grad_pointwise\u001b[39m.\u001b[39;49msum()\n\u001b[1;32m    292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     grad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((n_classes, n_dof), dtype\u001b[39m=\u001b[39mweights\u001b[39m.\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:46\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[39mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, [\"pic\", \"ni\"], \"dt\", 20)   # DecisionTree\n",
    "experiment(fake, correct, [\"pic\", \"ni\"], \"lr\", 20)   # LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing pic, cl, ni, lt and ahc columns improved performances !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

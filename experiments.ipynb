{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Fake Account Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.normalizer import csv_importer, csv_importer_full\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn import tree, metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to find demarcator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_demarcator(dataset):\n",
    "    \"\"\"\n",
    "    Restituisce l'indice del primo elemento non fake\n",
    "    :param dataset: il dataset\n",
    "    :return: l'indice\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    for elem in dataset:\n",
    "        if elem['fake'] == 1:\n",
    "            idx += 1\n",
    "        else:\n",
    "            break\n",
    "    return idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set train:test ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENT_TRAIN = 70"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading from file ./dataset/sources/user_fake_authentic_2class.csv...\n",
      "Loaded 65327 entries from source ./dataset/sources/user_fake_authentic_2class.csv\n"
     ]
    }
   ],
   "source": [
    "default_dataset = csv_importer_full(\"./dataset/sources/user_fake_authentic_2class.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into (balanced) training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now splitting dataset with ratio 70:30\n",
      "Loading complete.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now splitting dataset with ratio {PERCENT_TRAIN}:{100 - PERCENT_TRAIN}\")\n",
    "\n",
    "# Find demarcator (in the original datasets all fake accounts are at the beginning)\n",
    "idx = find_demarcator(default_dataset)\n",
    "# Separate fakes from real accounts\n",
    "fake = default_dataset[:idx]\n",
    "correct = default_dataset[idx:]\n",
    "# Shuffle both datatets (otherwise, train and validation sets would always contain the same elements)\n",
    "random.shuffle(fake)\n",
    "random.shuffle(correct)\n",
    "# Create training set\n",
    "train = fake[:int(len(fake) * (PERCENT_TRAIN / 100))]\n",
    "train += correct[:int(len(correct) * (PERCENT_TRAIN / 100))]\n",
    "# Create validation set\n",
    "validation = fake[int(len(fake) * (PERCENT_TRAIN / 100)):]\n",
    "validation += correct[int(len(correct) * (PERCENT_TRAIN / 100)):]\n",
    "# Shuffle both datasets\n",
    "random.shuffle(train)\n",
    "random.shuffle(validation)\n",
    "\n",
    "print(\"Loading complete.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nmedia     flw     flg   biol  pic  url     cl        cz     ni  \\\n",
      "0       136.0  2100.0  3300.0    8.0  1.0  0.0  139.0  0.000000  0.389   \n",
      "1         6.0    69.0   582.0    9.0  1.0  0.0  126.0  0.000000  0.000   \n",
      "2      1300.0   978.0   486.0  114.0  1.0  1.0  188.0  0.000000  0.000   \n",
      "3         2.0   136.0  7300.0    0.0  1.0  0.0    0.0  1.000000  0.000   \n",
      "4         0.0    16.0    82.0    0.0  1.0  0.0    0.0  0.000000  0.000   \n",
      "...       ...     ...     ...    ...  ...  ...    ...       ...    ...   \n",
      "45723     0.0     0.0    78.0    0.0  1.0  0.0    0.0  0.000000  0.000   \n",
      "45724     0.0   148.0  7300.0    0.0  1.0  0.0    0.0  0.000000  0.000   \n",
      "45725    39.0   820.0   733.0   69.0  1.0  1.0   50.0  0.055556  0.389   \n",
      "45726    57.0   976.0  7400.0   28.0  1.0  0.0  152.0  0.000000  0.167   \n",
      "45727   430.0   320.0   686.0    0.0  1.0  0.0   33.0  0.000000  0.444   \n",
      "\n",
      "              erl   erc     lt    ahc     pr   fo        cs      avgtime  fake  \n",
      "0       11.170000  0.87  0.000  1.222  0.056  0.0  0.030716   204.109146     0  \n",
      "1        7.250000  0.48  0.000  3.333  0.000  0.0  0.179772     0.066157     1  \n",
      "2        8.900000  0.33  0.333  0.833  0.000  0.0  0.064938   460.445892     0  \n",
      "3      133.820007  1.84  0.000  0.000  0.000  0.0  1.000000    57.071110     1  \n",
      "4        0.000000  0.00  0.000  0.000  0.000  0.0  1.000000     0.000000     1  \n",
      "...           ...   ...    ...    ...    ...  ...       ...          ...   ...  \n",
      "45723    0.000000  0.00  0.000  0.000  0.000  0.0  1.000000     0.000000     1  \n",
      "45724    0.000000  0.00  0.000  0.000  0.000  0.0  1.000000     0.000000     1  \n",
      "45725   24.240000  1.94  0.833  0.167  0.000  0.0  0.011623   860.859192     0  \n",
      "45726   18.719999  0.97  0.278  0.500  0.000  0.0  0.062241  1269.605347     0  \n",
      "45727    3.630000  0.35  0.000  0.000  0.000  0.0  0.010859   212.038101     1  \n",
      "\n",
      "[45728 rows x 18 columns]\n",
      "       nmedia     flw     flg   biol  pic  url     cl        cz     ni    erl  \\\n",
      "0       159.0   156.0  2000.0   31.0  1.0  0.0   24.0  0.055556  0.278  15.53   \n",
      "1       146.0   950.0  2800.0  157.0  1.0  1.0  387.0  0.000000  0.500   1.39   \n",
      "2        83.0   149.0   348.0    0.0  1.0  0.0   50.0  0.388889  0.389   4.33   \n",
      "3       915.0  3100.0  7400.0   64.0  1.0  0.0   41.0  0.555556  0.389   0.31   \n",
      "4         2.0   187.0  7400.0    0.0  1.0  0.0   15.0  0.000000  0.000  69.25   \n",
      "...       ...     ...     ...    ...  ...  ...    ...       ...    ...    ...   \n",
      "19593     8.0   135.0  3500.0    0.0  1.0  0.0   27.0  0.125000  0.375  14.07   \n",
      "19594    26.0   108.0   107.0    0.0  1.0  1.0   13.0  0.500000  0.278  15.38   \n",
      "19595    23.0   252.0   479.0    0.0  1.0  0.0   38.0  0.111111  0.167  21.58   \n",
      "19596   160.0   440.0  2000.0    0.0  1.0  0.0   30.0  0.222222  0.111   4.28   \n",
      "19597     6.0   200.0  7400.0    0.0  1.0  0.0   14.0  0.666667  0.000  13.42   \n",
      "\n",
      "        erc     lt    ahc   pr     fo        cs      avgtime  fake  \n",
      "0      1.35  0.778  1.389  0.0  0.111  0.050198   532.880676     0  \n",
      "1      0.08  0.111  0.833  0.0  0.000  0.426647   151.361252     0  \n",
      "2      0.48  0.278  0.222  0.0  0.000  0.141944   313.194427     1  \n",
      "3      0.02  0.833  0.333  0.0  0.000  0.307190   107.120216     1  \n",
      "4      4.55  0.000  0.500  0.0  0.500  0.408248    11.627083     1  \n",
      "...     ...    ...    ...  ...    ...       ...          ...   ...  \n",
      "19593  0.74  0.000  0.000  0.0  0.000  0.028057   397.047638     1  \n",
      "19594  0.72  0.000  0.222  0.0  0.000  0.193474   118.243118     0  \n",
      "19595  2.38  0.389  0.778  0.0  0.000  0.010769  1303.671875     0  \n",
      "19596  0.18  0.222  0.000  0.0  0.000  0.040053   176.548340     1  \n",
      "19597  0.58  0.000  0.000  0.0  0.000  0.400000  2541.919434     1  \n",
      "\n",
      "[19598 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame.from_dict(train)\n",
    "validation_df = pd.DataFrame.from_dict(validation)\n",
    "print(train_df)\n",
    "print(validation_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting complete.\n"
     ]
    }
   ],
   "source": [
    "# Default tree\n",
    "X, y = train_df.iloc[:, :-2], train_df.iloc[:, -1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "print(\"Fitting complete.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      9738\n",
      "           1       0.86      0.86      0.86      9860\n",
      "\n",
      "    accuracy                           0.86     19598\n",
      "   macro avg       0.86      0.86      0.86     19598\n",
      "weighted avg       0.86      0.86      0.86     19598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = validation_df.iloc[:, :-2], validation_df.iloc[:, -1]\n",
    "y_pred = clf.predict(X_val)\n",
    "print(metrics.classification_report(y_val,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First experiment with custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading from file ./dataset/sources/user_fake_authentic_2class.csv...\n",
      "Loaded 65327 entries from source ./dataset/sources/user_fake_authentic_2class.csv\n",
      "Loading complete.\n",
      "Fitting complete.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50      9738\n",
      "           1       0.51      0.51      0.51      9860\n",
      "\n",
      "    accuracy                           0.50     19598\n",
      "   macro avg       0.50      0.50      0.50     19598\n",
      "weighted avg       0.50      0.50      0.50     19598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_dataset = csv_importer(\"./dataset/sources/user_fake_authentic_2class.csv\")\n",
    "\n",
    "custom_fake = custom_dataset[:idx]\n",
    "custom_correct = custom_dataset[idx:]\n",
    "\n",
    "random.shuffle(custom_fake)\n",
    "random.shuffle(custom_correct)\n",
    "\n",
    "custom_train = custom_fake[:int(len(custom_fake) * (PERCENT_TRAIN / 100))]\n",
    "custom_train += custom_correct[:int(len(custom_correct) * (PERCENT_TRAIN / 100))]\n",
    "\n",
    "custom_validation = custom_fake[int(len(custom_fake) * (PERCENT_TRAIN / 100)):]\n",
    "custom_validation += custom_correct[int(len(custom_correct) * (PERCENT_TRAIN / 100)):]\n",
    "\n",
    "random.shuffle(custom_train)\n",
    "random.shuffle(custom_validation)\n",
    "\n",
    "print(\"Loading complete.\")\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(train)\n",
    "validation_df = pd.DataFrame.from_dict(validation)\n",
    "#print(train_df)\n",
    "#print(validation_df)\n",
    "\n",
    "custom_train_df = pd.DataFrame.from_dict(custom_train)\n",
    "custom_validation_df = pd.DataFrame.from_dict(custom_validation)\n",
    "#print(custom_train_df)\n",
    "#print(custom_validation_df)\n",
    "\n",
    "# Custom tree\n",
    "cX, cy = custom_train_df.iloc[:,:-2], custom_train_df.iloc[:,-1]\n",
    "cclf = tree.DecisionTreeClassifier()\n",
    "cclf = cclf.fit(cX, cy)\n",
    "print(\"Fitting complete.\")\n",
    "\n",
    "cX_val, cy_val = custom_validation_df.iloc[:,:-2], validation_df.iloc[:, -1]\n",
    "cy_pred = cclf.predict(cX_val)\n",
    "\n",
    "print(metrics.classification_report(cy_val,cy_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

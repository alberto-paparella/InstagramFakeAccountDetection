{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Fake Account Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.normalizer import csv_importer_full\n",
    "from dataset.utils import find_demarcator, shuffle_and_split\n",
    "from sequoia_comparison.utils import get_scores\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading from file dataset/sources/user_fake_authentic_2class.csv...\n",
      "Loaded 65327 entries from source dataset/sources/user_fake_authentic_2class.csv\n"
     ]
    }
   ],
   "source": [
    "default_dataset = csv_importer_full(\"dataset/sources/user_fake_authentic_2class.csv\")\n",
    "idx = find_demarcator(default_dataset)\n",
    "\n",
    "fake = default_dataset[:idx]\n",
    "correct = default_dataset[idx:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 26 - 04"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXP = 50 # Number of experiments\n",
    "MAX_ITER = 25000 # Maximum number of iterations for LR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using custom experiment functions not to mess up with the real experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Drop target columns from dataset\n",
    "'''\n",
    "def get_custom_dataset(train_df, validation_df, column_names=[]):\n",
    "    custom_train_df = train_df.drop(column_names, axis=1)\n",
    "    custom_validation_df = validation_df.drop(column_names, axis=1)\n",
    "\n",
    "    return custom_train_df, custom_validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "column_names: list of columns to drop from default dataset to get custom dataset\n",
    "\n",
    "modes:\n",
    " - \"dt\" => DecisionTree\n",
    " - \"lr\" => LogisticRegression\n",
    "'''\n",
    "def experiment(fake, correct, column_names=[], mode=\"dt\", n_iter=N_EXP):\n",
    "    avg_scores = {\n",
    "        'default': {'precision': 0, 'accuracy': 0},\n",
    "        'custom': {'precision': 0, 'accuracy': 0}\n",
    "    }\n",
    "\n",
    "    if mode == \"dt\":\n",
    "        print(f\"Calculating precision and accuracy metrics for Decision Trees over {n_iter} times\")\n",
    "    elif mode == \"lr\":\n",
    "        print(f\"Calculating precision and accuracy metrics for Logistic Regression (max_iter={MAX_ITER}) over {n_iter} times\")\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # Get new train_df and validation_df, same for default and custom\n",
    "        train_df, validation_df = shuffle_and_split(fake, correct)\n",
    "        custom_train_df, custom_validation_df = get_custom_dataset(train_df, validation_df, column_names)\n",
    "\n",
    "        # Default mode\n",
    "        if mode == \"dt\":\n",
    "            # Get new Decision Tree\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf = clf.fit(train_df.iloc[:, :-2], train_df.iloc[:, -1])\n",
    "        elif mode == \"lr\":\n",
    "            # Get new Logistic Regressor\n",
    "            clf = LogisticRegression(random_state=0, max_iter=MAX_ITER)\n",
    "            clf = clf.fit(train_df.iloc[:, :-2], train_df.iloc[:, -1])\n",
    "\n",
    "        # Get ground truth and predictions to measure performance\n",
    "        X_val, y_val = validation_df.iloc[:, :-2], validation_df.iloc[:, -1]\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        # Default scores\n",
    "        scores = get_scores(y_val, y_pred)\n",
    "        avg_scores['default']['precision'] += scores['precision']\n",
    "        avg_scores['default']['accuracy'] += scores['accuracy']\n",
    "\n",
    "        # Custom mode\n",
    "        if mode == \"dt\":\n",
    "            # Get new Decision Tree\n",
    "            clf = tree.DecisionTreeClassifier()\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-2], custom_train_df.iloc[:, -1])\n",
    "        elif mode == \"lr\":\n",
    "            # Get new Logistic Regressor\n",
    "            clf = LogisticRegression(random_state=0, max_iter=2500)\n",
    "            clf = clf.fit(custom_train_df.iloc[:, :-2], custom_train_df.iloc[:, -1])\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "        # Get ground truth and predictions to measure performance\n",
    "        X_val, y_val = custom_validation_df.iloc[:, :-2], custom_validation_df.iloc[:, -1]\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        # Custom scores\n",
    "        scores = get_scores(y_val, y_pred)\n",
    "        avg_scores['custom']['precision'] += scores['precision']\n",
    "        avg_scores['custom']['accuracy'] += scores['accuracy']\n",
    "\n",
    "        #print(f\"{i + 1}/{n_iter}\", end=\"\\r\")\n",
    "\n",
    "    # Averaging\n",
    "    for t in avg_scores.keys():\n",
    "        for s in avg_scores[t].keys():\n",
    "            avg_scores[t][s] /= n_iter\n",
    "\n",
    "    print('Done!\\n\\n')\n",
    "\n",
    "    print('default avg precision:', \"{:.5f}\".format(avg_scores['default']['precision']))\n",
    "    print('default avg accuracy:', \"{:.5f}\".format(avg_scores['default']['accuracy']))\n",
    "\n",
    "    print('custom avg precision:', \"{:.5f}\".format(avg_scores['custom']['precision']))\n",
    "    print('custom avg accuracy:', \"{:.5f}\".format(avg_scores['custom']['accuracy']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate impact upon removing single-attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact (bad/good) on performance is also evaluated from 1 (very small) to 5 (very big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nmedia', 'flw', 'flg', 'biol', 'pic', 'url', 'cl', 'cz', 'ni', 'erl',\n",
      "       'erc', 'lt', 'ahc', 'pr', 'fo', 'cs', 'avgtime', 'fake'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.from_dict(fake).columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nmedia - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85107\n",
      "default avg accuracy: 0.85409\n",
      "custom avg precision: 0.85007\n",
      "custom avg accuracy: 0.85256\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80997\n",
      "default avg accuracy: 0.79701\n",
      "custom avg precision: 0.80917\n",
      "custom avg accuracy: 0.79575\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['nmedia'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['nmedia'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85107\n",
    "# default avg accuracy: 0.85409\n",
    "# custom avg precision: 0.85007\n",
    "# custom avg accuracy: 0.85256\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80997\n",
    "# default avg accuracy: 0.79701\n",
    "# custom avg precision: 0.80917\n",
    "# custom avg accuracy: 0.79575"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing nmedia has a bad (1) impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flw - K (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85124\n",
      "default avg accuracy: 0.85425\n",
      "custom avg precision: 0.83437\n",
      "custom avg accuracy: 0.83749\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80913\n",
      "default avg accuracy: 0.79664\n",
      "custom avg precision: 0.81189\n",
      "custom avg accuracy: 0.79758\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['flw'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['flw'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85124\n",
    "# default avg accuracy: 0.85425\n",
    "# custom avg precision: 0.83437\n",
    "# custom avg accuracy: 0.83749\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80913\n",
    "# default avg accuracy: 0.79664\n",
    "# custom avg precision: 0.81189\n",
    "# custom avg accuracy: 0.79758"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flw has a bad (3) impact on performace (on DT, but positive (1) on LR) - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flg - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85122\n",
      "default avg accuracy: 0.85372\n",
      "custom avg precision: 0.80139\n",
      "custom avg accuracy: 0.80334\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80990\n",
      "default avg accuracy: 0.79647\n",
      "custom avg precision: 0.74312\n",
      "custom avg accuracy: 0.74923\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['flg'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['flg'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85122\n",
    "# default avg accuracy: 0.85372\n",
    "# custom avg precision: 0.80139\n",
    "# custom avg accuracy: 0.80334\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80990\n",
    "# default avg accuracy: 0.79647\n",
    "# custom avg precision: 0.74312\n",
    "# custom avg accuracy: 0.74923"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flg has a bad (5) impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### biol - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85121\n",
      "default avg accuracy: 0.85384\n",
      "custom avg precision: 0.84994\n",
      "custom avg accuracy: 0.85216\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.81020\n",
      "default avg accuracy: 0.79692\n",
      "custom avg precision: 0.80951\n",
      "custom avg accuracy: 0.79434\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['biol'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['biol'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# default avg precision: 0.85121\n",
    "# default avg accuracy: 0.85384\n",
    "# custom avg precision: 0.84994\n",
    "# custom avg accuracy: 0.85216\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.81020\n",
    "# default avg accuracy: 0.79692\n",
    "# custom avg precision: 0.80951\n",
    "# custom avg accuracy: 0.79434"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing biol has a bad (2) impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pic - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85187\n",
      "default avg accuracy: 0.85412\n",
      "custom avg precision: 0.85146\n",
      "custom avg accuracy: 0.85373\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80933\n",
      "default avg accuracy: 0.79695\n",
      "custom avg precision: 0.80736\n",
      "custom avg accuracy: 0.79608\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['pic'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['pic'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85187\n",
    "# default avg accuracy: 0.85412\n",
    "# custom avg precision: 0.85146\n",
    "# custom avg accuracy: 0.85373\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80933\n",
    "# default avg accuracy: 0.79695\n",
    "# custom avg precision: 0.80736\n",
    "# custom avg accuracy: 0.79608"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing pic has a bad (1) impact on performances - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### url - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85193\n",
      "default avg accuracy: 0.85450\n",
      "custom avg precision: 0.80305\n",
      "custom avg accuracy: 0.80322\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80950\n",
      "default avg accuracy: 0.79689\n",
      "custom avg precision: 0.78846\n",
      "custom avg accuracy: 0.76446\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['url'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['url'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85193\n",
    "# default avg accuracy: 0.85450\n",
    "# custom avg precision: 0.80305\n",
    "# custom avg accuracy: 0.80322\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80950\n",
    "# default avg accuracy: 0.79689\n",
    "# custom avg precision: 0.78846\n",
    "# custom avg accuracy: 0.76446"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing url has a bad (5) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cl - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85068\n",
      "default avg accuracy: 0.85394\n",
      "custom avg precision: 0.84934\n",
      "custom avg accuracy: 0.85289\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.81023\n",
      "default avg accuracy: 0.79724\n",
      "custom avg precision: 0.80808\n",
      "custom avg accuracy: 0.79600\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cl'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['cl'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85068\n",
    "# default avg accuracy: 0.85394\n",
    "# custom avg precision: 0.84934\n",
    "# custom avg accuracy: 0.85289\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.81023\n",
    "# default avg accuracy: 0.79724\n",
    "# custom avg precision: 0.80808\n",
    "# custom avg accuracy: 0.79600"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cl has a BAD (2) impact on performance - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cz - K (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85197\n",
      "default avg accuracy: 0.85413\n",
      "custom avg precision: 0.85172\n",
      "custom avg accuracy: 0.85401\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.81044\n",
      "default avg accuracy: 0.79701\n",
      "custom avg precision: 0.81327\n",
      "custom avg accuracy: 0.79789\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cz'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['cz'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85197\n",
    "# default avg accuracy: 0.85413\n",
    "# custom avg precision: 0.85172\n",
    "# custom avg accuracy: 0.85401\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.81044\n",
    "# default avg accuracy: 0.79701\n",
    "# custom avg precision: 0.81327\n",
    "# custom avg accuracy: 0.79789"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cz has a bad (1) impact on performace (on DT, but positive (1) on LR) - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ni - D (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85151\n",
      "default avg accuracy: 0.85431\n",
      "custom avg precision: 0.85176\n",
      "custom avg accuracy: 0.85452\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80882\n",
      "default avg accuracy: 0.79635\n",
      "custom avg precision: 0.81073\n",
      "custom avg accuracy: 0.79713\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['ni'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['ni'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85151\n",
    "# default avg accuracy: 0.85431\n",
    "# custom avg precision: 0.85176\n",
    "# custom avg accuracy: 0.85452\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80882\n",
    "# default avg accuracy: 0.79635\n",
    "# custom avg precision: 0.81073\n",
    "# custom avg accuracy: 0.79713"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing ni has a positive (1) impact on performance - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### erl - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85094\n",
      "default avg accuracy: 0.85421\n",
      "custom avg precision: 0.83422\n",
      "custom avg accuracy: 0.83776\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80922\n",
      "default avg accuracy: 0.79638\n",
      "custom avg precision: 0.80857\n",
      "custom avg accuracy: 0.79596\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['erl'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['erl'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85094\n",
    "# default avg accuracy: 0.85421\n",
    "# custom avg precision: 0.83422\n",
    "# custom avg accuracy: 0.83776\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80922\n",
    "# default avg accuracy: 0.79638\n",
    "# custom avg precision: 0.80857\n",
    "# custom avg accuracy: 0.79596"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing erl has a bad (3) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### erc - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85152\n",
      "default avg accuracy: 0.85438\n",
      "custom avg precision: 0.82527\n",
      "custom avg accuracy: 0.82676\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80965\n",
      "default avg accuracy: 0.79613\n",
      "custom avg precision: 0.80518\n",
      "custom avg accuracy: 0.79008\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['erc'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['erc'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85152\n",
    "# default avg accuracy: 0.85438\n",
    "# custom avg precision: 0.82527\n",
    "# custom avg accuracy: 0.82676\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80965\n",
    "# default avg accuracy: 0.79613\n",
    "# custom avg precision: 0.80518\n",
    "# custom avg accuracy: 0.79008"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing erc has a bad (3) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lt - D (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85046\n",
      "default avg accuracy: 0.85334\n",
      "custom avg precision: 0.85062\n",
      "custom avg accuracy: 0.85359\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80949\n",
      "default avg accuracy: 0.79639\n",
      "custom avg precision: 0.81202\n",
      "custom avg accuracy: 0.78764\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['lt'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['lt'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85046\n",
    "# default avg accuracy: 0.85334\n",
    "# custom avg precision: 0.85062\n",
    "# custom avg accuracy: 0.85359\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80949\n",
    "# default avg accuracy: 0.79639\n",
    "# custom avg precision: 0.81202\n",
    "# custom avg accuracy: 0.78764"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing lt has a positive impact on performace (on DT, but bad (1) on LR) - CONSIDER DROPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ahc - D (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85112\n",
      "default avg accuracy: 0.85402\n",
      "custom avg precision: 0.85137\n",
      "custom avg accuracy: 0.85406\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.81024\n",
      "default avg accuracy: 0.79684\n",
      "custom avg precision: 0.80922\n",
      "custom avg accuracy: 0.79540\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['ahc'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['ahc'], \"lr\")   # LogisticRegression\n",
    "\n",
    "#LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85112\n",
    "# default avg accuracy: 0.85402\n",
    "# custom avg precision: 0.85137\n",
    "# custom avg accuracy: 0.85406\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.81024\n",
    "# default avg accuracy: 0.79684\n",
    "# custom avg precision: 0.80922\n",
    "# custom avg accuracy: 0.79540"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing ahc has a positive (1) impact on performace (on DT, but bad (1) on LR) - CONSIDER DROPPING IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pr - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85159\n",
      "default avg accuracy: 0.85431\n",
      "custom avg precision: 0.84982\n",
      "custom avg accuracy: 0.85242\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.81059\n",
      "default avg accuracy: 0.79741\n",
      "custom avg precision: 0.80748\n",
      "custom avg accuracy: 0.79406\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['pr'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['pr'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85159\n",
    "# default avg accuracy: 0.85431\n",
    "# custom avg precision: 0.84982\n",
    "# custom avg accuracy: 0.85242\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.81059\n",
    "# default avg accuracy: 0.79741\n",
    "# custom avg precision: 0.80748\n",
    "# custom avg accuracy: 0.79406"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing pr has a bad (1) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fo - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85093\n",
      "default avg accuracy: 0.85436\n",
      "custom avg precision: 0.84995\n",
      "custom avg accuracy: 0.85327\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.81069\n",
      "default avg accuracy: 0.79696\n",
      "custom avg precision: 0.80898\n",
      "custom avg accuracy: 0.79585\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['fo'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['fo'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.851\n",
    "# default avg accuracy: 0.854\n",
    "# custom avg precision: 0.850\n",
    "# custom avg accuracy: 0.853\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 20 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.809\n",
    "# default avg accuracy: 0.797\n",
    "# custom avg precision: 0.808\n",
    "# custom avg accuracy: 0.795"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing fo has a bad (1) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cs - K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85129\n",
      "default avg accuracy: 0.85387\n",
      "custom avg precision: 0.85058\n",
      "custom avg accuracy: 0.85319\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.81070\n",
      "default avg accuracy: 0.79618\n",
      "custom avg precision: 0.78299\n",
      "custom avg accuracy: 0.78704\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['cs'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['cs'], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85129\n",
    "# default avg accuracy: 0.85387\n",
    "# custom avg precision: 0.85058\n",
    "# custom avg accuracy: 0.85319\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.81070\n",
    "# default avg accuracy: 0.79618\n",
    "# custom avg precision: 0.78299\n",
    "# custom avg accuracy: 0.78704"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing cs has a small bad (2) impact on performace - KEEP IT !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avgtime - D (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85033\n",
      "default avg accuracy: 0.85358\n",
      "custom avg precision: 0.85069\n",
      "custom avg accuracy: 0.85380\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80966\n",
      "default avg accuracy: 0.79600\n",
      "custom avg precision: 0.78179\n",
      "custom avg accuracy: 0.78733\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, ['avgtime'], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, ['avgtime'], \"lr\")   # LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION: removing flw has a positive (1) impact on performace (on DT, but bad on LR) - CONSIDER DROPPING IT !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second experiment with custom features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we fit (several) Decision Tree Classifier(s) (and Linear Regressors) removing from dataframes the attributes which seemed to worsen performance during the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85170\n",
      "default avg accuracy: 0.85395\n",
      "custom avg precision: 0.83050\n",
      "custom avg accuracy: 0.83394\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80960\n",
      "default avg accuracy: 0.79711\n",
      "custom avg precision: 0.78490\n",
      "custom avg accuracy: 0.75939\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, [\"flw\", \"cz\", \"ni\", \"lt\", \"ahc\", \"avgtime\"], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, [\"flw\", \"cz\", \"ni\", \"lt\", \"ahc\", \"avgtime\"], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85170\n",
    "# default avg accuracy: 0.85395\n",
    "# custom avg precision: 0.83050\n",
    "# custom avg accuracy: 0.83394\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80960\n",
    "# default avg accuracy: 0.79711\n",
    "# custom avg precision: 0.78490\n",
    "# custom avg accuracy: 0.75939"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONLUSION: IT FAILED !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we fit (several) Decision Tree Classifier(s) (and Linear Regressors) removing from dataframes the attributes which seemed to worsen performance (of Decision Trees only ! ) during the experiments.\n",
    "\n",
    "(HT: LR depends a lot more on MAX_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.85070\n",
      "default avg accuracy: 0.85364\n",
      "custom avg precision: 0.85122\n",
      "custom avg accuracy: 0.85394\n",
      "Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
      "Done!\n",
      "\n",
      "\n",
      "default avg precision: 0.80923\n",
      "default avg accuracy: 0.79600\n",
      "custom avg precision: 0.77695\n",
      "custom avg accuracy: 0.76550\n"
     ]
    }
   ],
   "source": [
    "# Experiments\n",
    "experiment(fake, correct, [\"ni\", \"lt\", \"ahc\", \"avgtime\"], \"dt\")   # DecisionTree\n",
    "experiment(fake, correct, [\"ni\", \"lt\", \"ahc\", \"avgtime\"], \"lr\")   # LogisticRegression\n",
    "\n",
    "# LOG\n",
    "# Calculating precision and accuracy metrics for Decision Trees over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.85070\n",
    "# default avg accuracy: 0.85364\n",
    "# custom avg precision: 0.85122\n",
    "# custom avg accuracy: 0.85394\n",
    "# Calculating precision and accuracy metrics for Logistic Regression over 50 times\n",
    "# Done!\n",
    "\n",
    "\n",
    "# default avg precision: 0.80923\n",
    "# default avg accuracy: 0.79600\n",
    "# custom avg precision: 0.77695\n",
    "# custom avg accuracy: 0.76550"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSIONS: removing ni, lt, ahc and avgtime improved DT but worsened LR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
